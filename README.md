# C√°lculo de Q* en un MDP usando la Ecuaci√≥n de Bellman

Este repositorio contiene un ejemplo sencillo de c√≥mo calcular la funci√≥n de valor acci√≥n √≥ptima **Q\*** en un **Proceso de Decisi√≥n de Markov (MDP)** utilizando programaci√≥n din√°mica y la ecuaci√≥n de Bellman.

El c√≥digo implementa:

- Una matriz de **probabilidades de transici√≥n**
- Una matriz de **recompensas**
- Un conjunto de **acciones posibles por estado**
- Inicializaci√≥n de valores **Q(s,a)**
- Actualizaciones iterativas mediante la **ecuaci√≥n de Bellman de optimalidad**
- Obtenci√≥n de la **pol√≠tica √≥ptima**

---

üß© Requisitos

Antes de ejecutar el script, instala las dependencias:

pip install -r requirements.txt

üßë‚Äçüíª Autor

Desarrollado por Gus como parte de su aprendizaje en Python e IA.
